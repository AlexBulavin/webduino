<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2020/12/19 17:30
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/TeachableMachine_video/TeachableMachine_video.html
-->

<!DOCTYPE html>
<head>
  <title>Teachable Machine</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script></head>  
</head>
<body>
<button onclick="location.href=location.pathname;">Front Camera</button>&nbsp;&nbsp;<button onclick="location.href='?back';">Rear Camera</button><br>
<video id="video" width="320" height="240" style="display:none" preload autoplay loop muted></video>
<br>
<table>
<tr><td>Model：</td><td>
<select id="kind">
<option value="image">image</option>
<option value="pose">pose</option>
</select>
</td></tr>
<tr><td>Model URL：</td><td><input type="text" id="modelUrl" size="40" value=""></td></tr>
<tr><td><a href="https://teachablemachine.withgoogle.com/train/image" target="_blank">Train Model</a></td><td><button type="button" onclick="LoadModel()">Start Recognition</button></td></tr>
</table>
<br>
<div id="result" style="color:red"></div>

<script type="text/javascript">
  var video = document.getElementById('video');
  var modelUrl = document.getElementById('modelUrl');
  var result = document.getElementById('result'); 
  var kind = document.getElementById('kind');
  let model; 
  
  async function LoadModel() {
	if (modelUrl.value=="") {
		result.innerHTML = "Please input Model Link.";
		return;
	}
	else
		result.innerHTML = "Please wait for loading model.";

	// the link to your model provided by Teachable Machine export panel
	const URL = modelUrl.value;
	const modelURL = URL + "model.json";
	const metadataURL = URL + "metadata.json";
	try {
		if (kind.value=="image") {
			model = await tmImage.load(modelURL, metadataURL);
		}
		else if (kind.value=="pose") {
			model = await tmPose.load(modelURL, metadataURL);
		}	
		maxPredictions = model.getTotalClasses();
		// load the model and metadata
		// Refer to tmImage.loadFromFiles() in the API to support files from a file picker
		// or files from your local hard drive
		// Note: the pose library adds "tmImage" object to your window (window.tmImage)
		// More API functions here:
		// https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

		result.innerHTML = "";
		startVideo();
	}
	catch (e){
		result.innerHTML = "Loading model failed.";
	}
  } 

  function startVideo() {
	if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
	  console.log("enumerateDevices() not supported.");
	  return;
	}

	var videoWidth = 320;
	var videoHeight = 240;
	
    var back = {audio: false,video: {facingMode: 'user',width: videoWidth,height: videoHeight}};
	navigator.mediaDevices.enumerateDevices()
		.then(function(devices) {
		  devices.forEach(function(device) {
			  if (device.kind=="videoinput"&&device.label.includes("facing back")) {
				if (device.deviceId=='')
					back = {audio: false,video: {facingMode: 'environment',width: videoWidth,height: videoHeight} };
				else
					back = {audio: false,video: {deviceId: {'exact':device.deviceId}, facingMode: 'environment',width: videoWidth,height: videoHeight} };
			  }
		  });
		
		
		if (location.search.toLowerCase().indexOf("?back")!=-1)
		  var userMedia = back;
		else
		  var userMedia = {audio: false,video: {facingMode: 'user',width: videoWidth,height: videoHeight}};

		video.style.display="block";
		navigator.mediaDevices
		  .getUserMedia(userMedia)
		  .then(stream => {
			video.srcObject = stream
			video.onloadedmetadata = () => {       
				video.play(); 
				result.innerHTML = "";
				setTimeout(function(){predict(); }, 100);
			}
		 })  
	})   
  }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
	var data = "";
	var maxClassName = "";
	var maxProbability = "";
		if (kind.value=="image")
			var prediction = await model.predict(video);
		else if (kind.value=="pose") {
			var { pose, posenetOutput } = await model.estimatePose(video);
			var prediction = await model.predict(posenetOutput);
		}		
        for (let i = 0; i < maxPredictions; i++) {
			if (i==0) {
				maxClassName = prediction[i].className;
				maxProbability = prediction[i].probability;
			}
			else {
				if (prediction[i].probability>maxProbability) {
					maxClassName = prediction[i].className;
					maxProbability = prediction[i].probability;
				}
			}
            data += prediction[i].className + ": " + prediction[i].probability.toFixed(2) + "<br>";
        }
	result.innerHTML = data + "Result: " + maxClassName + " (" + maxProbability + ")";
	setTimeout(function(){predict(); }, 100);
    }
</script>

</body>
</html>
